{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if branch. x: tensor(-2., requires_grad=True)\n",
      "val:  -0.0\n",
      "grad 0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "def my_relu(x: torch.FloatTensor) -> torch.FloatTensor:\n",
    "    # set_trace() # <-- this!\n",
    "    if x < 0: \n",
    "        print(\"if branch. x:\", x)\n",
    "        return x * 0\n",
    "    return x\n",
    "x = torch.tensor(-2., requires_grad=True)\n",
    "res = my_relu(x)\n",
    "res.backward()\n",
    "\n",
    "print(\"val: \", res.item())\n",
    "print(\"grad\", x.grad.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models\n",
    "\n",
    "#from ipdb import set_trace # <-- for debugging\n",
    "\n",
    "DEVICE = torch.device(\n",
    "    \"cuda:0\" if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(3,3)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a + a @ a.t();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.to(DEVICE)\n",
    "a + a @ a.t();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.cpu(); # a.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(20, 64, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = torch.rand(16,1,24,24)\n",
    "model(batch); # forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(20,64,5)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        return F.adaptive_avg_pool2d(x,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    " \n",
    "try:\n",
    "    from collections import OrderedDict\n",
    "except ImportError:\n",
    "    OrderedDict = dict\n",
    "\n",
    "def bn_conv_relu(in_channels, out_channels, kernel_size=5):\n",
    "    return nn.Sequential(\n",
    "        nn.BatchNorm2d(in_channels),\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "\n",
    "model = nn.Sequential(\n",
    "    OrderedDict({\n",
    "        \"conv1\": bn_conv_relu(1,20,7),\n",
    "        \"conv2\": bn_conv_relu(20,64),\n",
    "        \"aap\": nn.AdaptiveAvgPool2d(1),\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv1): Sequential(\n",
       "    (0): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv2d(1, 20, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (aap): AdaptiveAvgPool2d(output_size=1)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=1, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "lin = nn.Linear(1,3,bias=True)\n",
    "print(lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[0.5995],\n",
       "                      [0.1643],\n",
       "                      [0.1482]])),\n",
       "             ('bias', tensor([-0.9066, -0.9253, -0.1082]))])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.5995],\n",
      "        [0.1643],\n",
      "        [0.1482]], requires_grad=True)\n",
      "\n",
      "Parameter containing:\n",
      "tensor([-0.9066, -0.9253, -0.1082], requires_grad=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p in lin.parameters():\n",
    "    print(p)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Linear(in_features=1, out_features=3, bias=True) with uniform\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def init_weights(module):\n",
    "    if isinstance(module, nn.Linear):\n",
    "        print(f\"Initializing {module} with uniform\")\n",
    "        nn.init.uniform_(module.weight)\n",
    "        \n",
    "lin.apply(init_weights);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.MNIST(\"data/raw/\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28 at 0x7FA1786E0C10>, 0)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/0lEQVR4nGNgGHhgPP/vfCMccgbv/vz58xa7nNnjv3/ev/xjyYYpxWXz4M/fP6dC/vytgggwIUnOPCDDwMBgxHOQQRdD0tibkfFQKeOL85OYGLG5ZTOPd6UoA8Pfz2gOVlv69+WFEAj775+lKHLsm/58cBeWgUkeRpG0/PPHHs5Blzz2dx+C8//vEWTX+hj834SQ/Pf/ArLG0D/PJOHWt//dxYMqeR8u1/znoTsDquREKMtg6Z+1DKgg7O9DCKPo3d9FaHIMoX9+TjKQDd308O/95RaYkn/+PL3+58+fI03oUgwMMsf//Pn758/LiZhSDAwMkg1//v7pVcUqR1cAAKxwbkTVIzd2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FA179A169A0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Label: {dataset[1][1]}\")\n",
    "dataset[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=4,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML is model + loss + optimizer\n",
    "model # from above\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(\n",
    "    [s\n",
    "        {\"params\": model.conv1.parameters(), \"lr\": 0.001},\n",
    "        {\"params\": model.conv2.parameters()}\n",
    "    ],\n",
    "    lr=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, loss_fn, optimizer, train_dl, valid_dl, n_epochs: int):\n",
    "    for epoch in range(n_epochs):\n",
    "        # TRAIN\n",
    "        model.train()\n",
    "        for x, y in train_dl:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            y_ = model(x)\n",
    "            loss = loss_fn(y, y_)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        # EVAL\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x, y in valid_dl:\n",
    "                x, y = x.to(DEVICE), y,to(DEVICE)\n",
    "                y_ = model(x)\n",
    "                loss = loss_fn(y, y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.DataParallel(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.models.resnet18(pretrained=True)\n",
    "torchvision.models.densenet121(pretrained=True)\n",
    "torchvision.models.inception_v3(pretrained=True)\n",
    "torchvision.models.squeezenet1_1(pretrained=True);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
