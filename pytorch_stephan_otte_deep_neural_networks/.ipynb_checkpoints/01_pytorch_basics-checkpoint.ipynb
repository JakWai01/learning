{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init, helpers, utils, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision as optim\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors\n",
    "\n",
    "tensors - the atoms of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors in numpy and pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import multi_dot as mdot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy\n",
    "np.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch\n",
    "torch.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# numpy \n",
    "X = torch.rand((5, 3))\n",
    "X\n",
    "\n",
    "    \n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# pytorch \n",
    "Y = torch.rand(5,3)\n",
    "Y\n",
    "\n",
    "    \n",
    "print(type(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0340, 1.0271, 1.0862],\n",
       "        [1.0271, 1.3567, 1.3139],\n",
       "        [1.0862, 1.3139, 2.1835]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy\n",
    "X.T @ X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4583, 1.7847, 1.0369],\n",
       "        [1.7847, 2.6678, 1.3518],\n",
       "        [1.0369, 1.3518, 1.3196]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch \n",
    "Y.t() @ Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.045792  , -2.6697721 , -0.40611708],\n",
       "       [-2.6697721 ,  3.5284803 , -0.7951296 ],\n",
       "       [-0.40611708, -0.7951296 ,  1.1384732 ]], dtype=float32)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy \n",
    "inv(X.T @ X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.2259, -2.3797, -0.8828],\n",
       "        [-2.3797,  2.1194, -0.3012],\n",
       "        [-0.8828, -0.3012,  1.7599]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch\n",
    "torch.inverse(Y.t() @ Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More on Pytorch Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations are also available as methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 1., 1.],\n",
       "        [1., 2., 1.],\n",
       "        [1., 1., 2.]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.eye(3)\n",
    "A.add(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any operation that mutates a tensor in-place has a _ suffix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 1., 1.],\n",
       "        [1., 2., 1.],\n",
       "        [1., 1., 2.]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.add_(1)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works as expected/like numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 1., 1.],\n",
       "        [1., 2., 1.],\n",
       "        [1., 1., 2.]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 1., 1.])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 1., 1.],\n",
       "        [1., 2., 1.]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [2., 1.],\n",
       "        [1., 2.]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[:, 1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.eye(3)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch --> numpy\n",
    "A.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy --> torch \n",
    "torch.from_numpy(np.eye(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to v0.4 PyTorch used the class Variable to record gradients. Your had to wrap Tensors in Variables. Variables behaved like Tensors. With v.0.4 Tensor can record gradients directly if you tell it to do so, e.g. torch.ones(3, requires_grad=True). There is no need for Variable anymore. \n",
    "\n",
    "Ref: \n",
    "\n",
    "- https://pytorch.org/docs/stable/autograd.html\n",
    "- https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import autograd # you rarely use it directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.ones(1)\n",
    "w.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.ones(1) * 2\n",
    "z.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = w + z\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-177-bf01478f3b7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# What is goind to happen here?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtotal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# What is goind to happen here?\n",
    "total.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.ones(1, requires_grad=True)\n",
    "w.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = w + z\n",
    "total.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    total = w + z\n",
    "    \n",
    "total.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But what about the GPU?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do I use the GPU?\n",
    "\n",
    "If you have a GPU make sure that the right pytorch is installed \n",
    "\n",
    "    conda install pytorch torchvision cuda91 -c pytoch\n",
    "    \n",
    "Check https://pytorch.org/ for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a GPU you should get something like: device(type='cuda', index=0)\n",
    "\n",
    "You can move data to the GPU by doing .to(device)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.eye(3)\n",
    "data.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: before v0.4 one had to use .cuda() and .cpu() to move stuff to and from the GPU. This littered the code with many:\n",
    "        \n",
    "    if CUDA:\n",
    "        model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinReg with PyTorch, Gradient Descent, and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f545691cf70>]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD4CAYAAAAEhuazAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVzklEQVR4nO3de4xc5XnH8d8zaxvVrZtuDMGu1xcsE1Ts3uyVMeKfuNDGVFYdcKkMVYIUEleVURspfwSK5FaukFAv6UV1kropCpG41KlBRg6EAKLiHxzYtaLWxnHqGhamdoIxG9WSEevdefrHnDXD+MzOOTPnzLl9PxLanTMzu+8K+J13nvOc9zV3FwCgWmpZDwAAMHiEPwBUEOEPABVE+ANABRH+AFBB87IeQFRXXnmlr1q1KuthAEChjI+Pv+vuV7UfL0z4r1q1SmNjY1kPAwAKxcwmwo5T9gGACiL8AaCCCH8AqCDCHwAqiPAHgAoi/AGgggh/AMip8YlJ7X3ppMYnJhP/2YXp8weAKhmfmNQffvOwpqYbWjCvpke/sEkbVg4n9vOZ+QNADh0+dU5T0w01XLo43dDhU+cS/fmEPwDk0KbVi7VgXk1DJs2fV9Om1YsT/fmUfQAghzasHNajX9ikw6fOadPqxYmWfKSEZv5m9rCZvWNmR1uOfdzMnjez/w6+Drc8d7+ZnTSzE2b26STGAABls2HlsHZtXpN48EvJlX2+JWlL27H7JL3o7tdKejF4LDO7XtIOSWuD93zNzIYSGgcAIIJEwt/dX5b0XtvhbZIeCb5/RNJnWo4/4e4fuPsbkk5K2pjEOAAA0aR5wfdqdz8jScHXTwTHl0l6u+V19eAYAGBAsuj2sZBjHvpCs51mNmZmY2fPnk15WABQHWmG/0/NbKkkBV/fCY7XJS1ved2IpNNhP8Dd97n7qLuPXnXVZRvRAAB6lGb4Py3p7uD7uyUdbDm+w8yuMLNrJF0r6dUUxwEAaJNIn7+ZPS7pU5KuNLO6pD+X9JCk/WZ2j6S3JN0hSe5+zMz2S3pd0rSkXe4+k8Q4AADRJBL+7n5nh6du7vD6ByU9mMTvBgDEx/IOAFBBhD8AVBDhDwAVRPgDQArS3IglCazqCQAJS3sjliQw8weAhKW9EUsSCH8ASFjaG7EkgbIPACQs7Y1YkkD4A0AKNqwczmXoz6LsAwAVRPgDQAUR/gAQU957+KOg5g8AMRShhz8KZv4AEEMRevijYOYPADFsWr1Y84Zqujjd0NBQs4d/fGLyUlunpFy3eM4i/AHkUmug5i5E3S99PfGT89pz6JimphuaVzPJTNMz+S8JEf4AcifPdfXDp85puuFySTMN17NHz3xYBppxSc3nZktCeRl3O2r+AHInz3X19qUbbl239MPHQ6b5OV/WYRYzfwC5MxuwF6cbuQzR7etH5MHXDSuHdd2SRdT8AaBf3dbGyep6QHs5avv6kUvjbR1HnkN/FuEPIJc6rY2T5fWAsHJUEYI+DDV/AIWS5fWAIizVHBUzfwCFkuX1gCIs1RyV+Wy/as6Njo762NhY1sMAkAO5vgcgZ8xs3N1H249T9gFQKAR/Mij7ACiMvN78VcQTEuEPYCCiBuRcr8tjt01eT0jdEP4AUhc1ILu9Lo83f+XxhBQF4Q8gdVEDstvr8thtk8cTUhSEP4BUtJZvogZklNflbWP0PJ6QoqDVE0Diwso3UrQ1b4p48TTPOrV6MvMHkLiw8s2uzWsihXneZvZlRZ8/gK7ibljeugzCUM10+mfvF3qz8zKi7ANgTr22Mo5PTOrAkbr+fbx+2c5WnUo7lHySR9kHQE96bWXcsHK4uevVzOWLsIWdTIraL19UlH0AzKmflSzD3ttpVc5+V+uMW5qqOmb+AObU3sooSXtfOhmpNNOpDTKsnbOffnk+NcSXevib2ZuSzkuakTTt7qNm9nFJ/yZplaQ3Jf2Bu3O6BnIgrO4+24HTS8iG7XIVdkLop1++qHfZZmlQM//N7v5uy+P7JL3o7g+Z2X3B468MaCwAOugW7v2EbPtJJex9vbZ5FvUu2yxlVfbZJulTwfePSPoPEf5A5rqFe68hm3ZZpqh32WZpEOHvkr5vZi7pn919n6Sr3f2MJLn7GTP7RNgbzWynpJ2StGLFigEMFai2buHea8gOoizDzWHxDCL8b3L300HAP29mP4r6xuBEsU9q9vmnNUAATVHCvZeQpSyTP6mHv7ufDr6+Y2ZPSdoo6admtjSY9S+V9E7a4wAQTRozaMoy+ZNqn7+Z/byZLZr9XtLvSDoq6WlJdwcvu1vSwTTHASBZvfTUb1g5HHl9H6Qv7Zn/1ZKeMrPZ3/WYu3/PzF6TtN/M7pH0lqQ7Uh4HgITQU18OqYa/u5+S9Oshx89JujnN3w0gHfTUlwPLOwAlk/YyB/0s94D8YHkHoEQGUZLh4m05EP5AiQyqJENPffFR9gFKhJIMomLmD5RIXksybNKSP4Q/UDJRSjKDDGNaQ/OJ8AcqZnxiUnfue0UXZ1zzh0yP77wx8raMLLdcHoQ/UDEHjtQ1NdNcKmtqxnXgSD3SJ4VeZ++s65NPhD9QMdblcZg4s/ewdfvzeB2i6gh/IGV5u9h5+/oRfWe8fmkmfvv6ka7viTp77/QJgdbQ/CH8gRTl4WJn2Ez88S/Gm4lHnb1T3y8Owh9IUdZh2M9MPOyk0e091PeLg/AHUpR1GPZ68un1Ewv1/eIg/IEUZR2GvZ58+vnEQn2/GAh/IGVZhmGvJ5+sP7EgfeZejK1xR0dHfWxsLOthAJWRty4l9MbMxt19tP04M3+gpPoNb8o35Ub4AyWUhxZT5BtLOgMlFHbBFmhF+AMlNLxwgWpmqol1/RGO8AcGpNe9deO+b3xiUnsOHVPDXbWaaffWtZR8cBlq/sAA9FqD7+V9rSUfk2vywlRSfwZKhJk/MAC91uB7eR9bOSIKZv7AAPR601Tc9822d+7eulaTF6bo0UdH3OQFDEivffdR30d7J8JwkxegbO9a7fWmqdb3zTX+rFcQRbEQ/qiMLGfGSZx0HvvBW9p98Kga7qHjZz0exEH4ozL6mRn3E95JnHTGJya1++BRTTeCvXdDxp/1CqIoFsIfldHrzLjf8E6iHHP41DnNND68PlczCx0/6/EgKsIfldHrzLhbeHf7VNB+0hleuEB7XzoZe4nlK+bXNHWxoVrNtGfbOkIefSH8USm9zIzn+sQQ5VNB60lneOEC7Tl0jB2ykDnCH+hiruCNWtKZPensfekkO2QhFwh/QN1LN52CN+51BDpykBfc5IXK6/eCbtxOIHbIwiBxkxfQQb/dOHHLMZRvkAcs7IbKm2shtF6XYQbyLrOZv5ltkfQPkoYkfdPdH8pqLKi29m6c1pUzWSsHZZVJ+JvZkKS9kn5bUl3Sa2b2tLu/nsV4gNlQbw377etHYpWDqOWjSLKa+W+UdNLdT0mSmT0haZskwh+Zaa/9uxS5M2cQ6wZxckGSsgr/ZZLebnlcl3RD+4vMbKeknZK0YsWKwYwMldXehrl9/Yi2rx+JFLidLhonFdgs14ykZRX+FnLssp5Td98naZ/UbPVMe1Cotk43c0UJ2bD+/SQDm+WakbSswr8uaXnL4xFJpzMaC3BJP2vut584+rmbtx03hyFpWYX/a5KuNbNrJP2vpB2S7spoLKiItGvm7SeOJAObtX2QtEzC392nzexeSc+p2er5sLsfy2IsqIZOJZgka/Jh5aIkA5ubw5CkzPr83f0ZSc9k9ftRLWE1cymZPv65avsENvKKO3xRWHHuvh1euEA1M9Va7uLtdEKIK6mfAwwSa/ugkOJ00oxPTGrPoWOaabiGaqbdW9deem0SNXkuxqKICH8UUpzWx9nXuiR31+SFKUnxa/Kdrg9wMRZFRPijkOLMtud6bdSafLdPGtT2UTSEPwopzmw7iZk5N1mhbAh/FFac2Xan10Zt9aSuj7Ih/FFZcXr/qeujbAh/VFbc3n/q+igT+vxRWWE7eMXt2WenLxQVM39UVtgOXsMLF+RqDX8gLYQ/ci/NBdnCdvDavXWtJi9M9byGP1AEhD9ybRCz6/YQn7wwpV2b13R9Hx1AKDLCH7mW1uy69dNEtxDnzl6UEeGPXEtjdh32aaJTiHNnL8qK8Efu3b5+RBZ8TWIN/rBPE7s2rwn9WdT1UVaEP3KrfdZ9+/qRy45FvTjbKql1gYAiI/yRW62z7qmWnvtLxy42tPvgUTXcY10MHvS6QEAeEf7IreGFC9Tw5vcNbz6+bsmiSzNxM9NMw+VqngjilGSSWBcIKDLCH7k1eWFKJsnVvBV98sLUR2bi59+/qG+8fEqS1FDz5AAgGpZ3QG5tWr1YV8xvLr+wYP6H9fYNK4e1a/MaLfq5+apZ87U106VNWgB0x8wfudWt3s7FWKB3hD9yrds6/L10+wAg/FFALKgG9I+aPwon7rLLAC5H+COWQa9fH/b7wtbhBxAPZR9ENshyy/jEpJ48Utd3xt7WdOOjN3Fx4xXQP8IfkQ1qnZvZk8wHFxsK7vG67Pdx4xXQH8o+iCypcku30tHsSWY2+E29/T62WAQ6Y+aPyJIot0QpHbX27w8N1fT7G0a0PVjRM8nfA1QZ4Y9Y+i23RCkdJXGSYSlmYG6EPwZq0+rFmjf04ay+Uymn35MMd/8CcyP80ZeeNlZx/+jXFNARBMyN8EfPeqmrHz51TtPBMswzDU+1HENHENAZ3T7oyfjEpP7+hR/rg4vx7rTlBi0gH5j5I5LW8o6kSzP+2bX2h2qm0z97X+MTk+yMBRQA4Y+u2ss729ePXOqkqZn0q8s+puM/Oa/HX31LB47Uu5Z/KMcA2aPsU1JJ3uDU3jbp0qXSzYJ5Na1d9jFNz7DQGlAkqc38zewvJH1R0tng0J+5+zPBc/dLukfSjKQ/cffn0hpHFSV9g1N72+T29c2brlrLQE8eqdNWCRRI2mWfv3P3v2k9YGbXS9ohaa2kX5b0gpl90t1nUh5LZUS5wSlOi+aGlcPavXWtnj16RreuW/qR9XVmUccHiiWLmv82SU+4+weS3jCzk5I2Snolg7GUUrcbnMI+GUjqGN7jE5Pac+iYpqYbeu3N93TdkkWhd+US+kBxpB3+95rZ5ySNSfqyu09KWibpcMtr6sGxy5jZTkk7JWnFihUpD7U8unXUtH8yOHCkrieP1EPLRLMtnSyVAJRLX+FvZi9IWhLy1AOSvi7pLyV58PVvJX1ezUUa24Xe6unu+yTtk6TR0dH0bgctoblm4u2fDEwKDff2pZVr9OYDpdFX+Lv7LVFeZ2b/IulQ8LAuaXnL0yOSTvczjrLraQmFObR/MpCkAyEXbFuXVq5JumnNlfrSLZ9k1g+UQJrdPkvd/Uzw8DZJR4Pvn5b0mJl9Vc0LvtdKejWtcRRda32+ZqY929bprhv6L4G1fzIIKxO1f0Ig+IHySLPm/1dm9htqlnTelPRHkuTux8xsv6TXJU1L2kWnT2et9fmGu3YfPBp6wbVfrSeD1k8adPEA5ZRa+Lv7Z+d47kFJD6b1u8tk0+rFqpmpEayA2Uh5MbSwTqBdm9ek8rsAZIc7fHNuw8ph7dm2TvNqppqkBfPTveAado9Av9hOEcgf1vYpgLtuWKHrlixKpfzSfjE56U1Q2E4RyCfCvyDSuImqUzAnWednO0Ugnwj/CusUzFFPNFFaUNlOEcgnwr/C+gnmqOUc1u8H8onwr6jZWfvurWs1eWEqdjDHKeew7g+QP4R/BSVxEZZyDlBshH8FJXERlnIOUGyEfwX1MmsPu7hLOQcoLsK/pObqxIk7a6dXHygfwj+mpFfYTEOUsI4za6dXHygfwj+GosyAkw5rLu4C5UP4x1CUGXDSYc3FXaB8CP8YijIDTiOsubgLlIu5F2N3xNHRUR8bG8t6GIWo+QPALDMbd/fR9uPM/GMa5AyYEw2AtBD+OVWUi8sAionNXHIqjU1VAGAW4Z+QXnarmus9sxeXh0y5vrgMoJgo+ySglxJNt/fQXgkgTYR/Anrp/4/yHtorAaSFsk8CeinRUNYBkCX6/BPSS1smrZwA0kaffwT9hHEvJRrKOgCyQvgH6KsHUCXU/AP01QOoEsI/kMYF2F56/wFgECj7BJLuq6eMBCDPCP8WSV6ALcra/wCqibJPSujjB5BnzPxTwvIMAPKM8E8RffwA8oqyDwBUEOEPABVE+ANABRH+AFBBfYW/md1hZsfMrGFmo23P3W9mJ83shJl9uuX4BjP7r+C5fzQz62cMAID4+p35H5V0u6SXWw+a2fWSdkhaK2mLpK+Z2VDw9Ncl7ZR0bfDPlj7HAACIqa/wd/fj7n4i5Kltkp5w9w/c/Q1JJyVtNLOlkn7R3V/x5kYC35b0mX7GAACIL62a/zJJb7c8rgfHlgXftx8PZWY7zWzMzMbOnj2bykABoIq63uRlZi9IWhLy1APufrDT20KO+RzHQ7n7Pkn7pOZOXl2GCgCIqGv4u/stPfzcuqTlLY9HJJ0Ojo+EHAcADFBaZZ+nJe0wsyvM7Bo1L+y+6u5nJJ03s01Bl8/nJHX69AAASEm/rZ63mVld0o2Svmtmz0mSux+TtF/S65K+J2mXu88Eb/tjSd9U8yLw/0h6tp8xAADis2bTTf6Njo762NhY1sMAgEIxs3F3H20/zh2+AFBBhD8AVFDpw59N1AHgcqXezIVN1AEgXKln/mGbqAMASh7+bKIOAOFKXfZhE3UACFfq8JfYRB0AwpS67AMACEf4A0AFEf4AUEGEPwBUEOEPABVE+ANABRVmSWczOytpIutxzOFKSe9mPYgM8ffz9/P359NKd7+q/WBhwj/vzGwsbM3squDv5+/n7y/W30/ZBwAqiPAHgAoi/JOzL+sBZIy/v9r4+wuGmj8AVBAzfwCoIMIfACqI8E+Imf21mf3IzP7TzJ4ys1/KekyDZGZ3mNkxM2uYWaFa3vphZlvM7ISZnTSz+7Iez6CZ2cNm9o6ZHc16LINmZsvN7CUzOx78t/+nWY8pDsI/Oc9LWufuvybpx5Luz3g8g3ZU0u2SXs56IINiZkOS9kq6VdL1ku40s+uzHdXAfUvSlqwHkZFpSV9291+RtEnSriL9+yf8E+Lu33f36eDhYUkjWY5n0Nz9uLufyHocA7ZR0kl3P+XuU5KekLQt4zENlLu/LOm9rMeRBXc/4+5Hgu/PSzouaVm2o4qO8E/H5yU9m/UgkLplkt5ueVxXgf7nR3LMbJWk35T0g2xHEl3pt3FMkpm9IGlJyFMPuPvB4DUPqPlx8NFBjm0Qovz9FWMhx+idrhgz+wVJByR9yd3/L+vxREX4x+Dut8z1vJndLWmrpJu9hDdQdPv7K6guaXnL4xFJpzMaCzJgZvPVDP5H3f3JrMcTB2WfhJjZFklfkfR77n4h6/FgIF6TdK2ZXWNmCyTtkPR0xmPCgJiZSfpXScfd/atZjycuwj85/yRpkaTnzeyHZvaNrAc0SGZ2m5nVJd0o6btm9lzWY0pbcIH/XknPqXmxb7+7H8t2VINlZo9LekXSdWZWN7N7sh7TAN0k6bOSfiv4f/6HZva7WQ8qKpZ3AIAKYuYPABVE+ANABRH+AFBBhD8AVBDhDwAVRPgDQAUR/gBQQf8PhEDNvqHjo48AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "n_features = 1\n",
    "n_samples = 100\n",
    "\n",
    "X, y = make_regression(\n",
    "    n_samples=n_samples,\n",
    "    n_features=n_features,\n",
    "    noise=10,\n",
    ")\n",
    "\n",
    "fix, ax = plt.subplots()\n",
    "ax.plot(X,y, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(X).float()\n",
    "y = torch.from_numpy(y.reshape((n_samples, n_features))).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "class LinReg(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.beta = nn.Linear(input_dim, 1, bias=True)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.beta(X)\n",
    "    \n",
    "    \n",
    "print(type(X))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-47e8f035522b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# <-- here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "# Move everything to GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = LinReg(n_features).to(device) # <-- here\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "X, y = X.to(device), y.to(device) # <-- here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-189-253cccb226d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-187-67c4bef72413>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtens_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "# Train step \n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "\n",
    "y_ = model(X)\n",
    "loss = criterion(y_, y)\n",
    "\n",
    "loss.backward(loss)\n",
    "optimizer.step()\n",
    "\n",
    "# Eval\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_ = model(X)\n",
    "    \n",
    "# Vis \n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(X.cpu().numpy(), y_.cpu().numpy(), \".\", label=\"pred\")\n",
    "ax.plot(X.cpu().numpy(), y.cpu().numpy(), \".\", label=\"data\")\n",
    "ax.set_title(f\"MSE: {loss.item():0.1f}\")\n",
    "ax.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
